{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and visualizations of my Facebook Messenger chat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import int64, polyfit, nan\n",
    "from math import floor, ceil\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "%matplotlib inline\n",
    "my_name = 'Andreas Vija'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_msgs = pd.read_csv('data.csv').fillna('')\n",
    "csv_msgs.info()\n",
    "csv_msgs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_msgs = csv_msgs.copy()\n",
    "all_msgs['time'] = csv_msgs['time'].astype('datetime64[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = all_msgs[['time', 'text']]\n",
    "df = df.set_index('time')\n",
    "df = df.resample('w').count()\n",
    "\n",
    "df.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a large unnatural dip in early 2017 and two peaks in mid-2016 and Jan 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only <5% of my messages were sent before 2015, thus leaving out 2010-2014 helps make some graphs easier to read while losing very little data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_msgs = csv_msgs.copy()\n",
    "_2015 = pd.to_datetime('2015-01-01 00:00:00', infer_datetime_format=True).timestamp()\n",
    "most_msgs = most_msgs[most_msgs['time'] > int(_2015)]\n",
    "most_msgs['time'] = most_msgs['time'].astype('datetime64[s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chats with the most messages\n",
    "As evident later in certain \"chat activity over time\" graphs, big chunks of messages are actually missing from multiple chats, making these message counts not accurate, although they paint a fair enough picture of the most active chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chats = all_msgs.copy()[['thread', 'names', 'groupchat']].groupby(['thread', 'names'], as_index=False)\n",
    "\n",
    "types = chats.max()[['groupchat']]\n",
    "counts = chats.count().rename(columns={'groupchat': 'message count'})\n",
    "chats = pd.concat([types, counts], axis=1)\n",
    "\n",
    "chats = chats.sort_values('message count', ascending=False)\n",
    "chats = chats.reset_index()[['thread', 'groupchat', 'names', 'message count']]\n",
    "\n",
    "chats[['thread', 'groupchat', 'message count']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 chats with exactly/almost exactly 10,000 messages is suspicious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## People with the most messages in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = all_msgs.copy()[['sender', 'groupchat']]\n",
    "df = df.groupby('sender').count()\n",
    "df = df.rename(columns={'groupchat': 'messages_available'})\n",
    "df = df.sort_values('messages_available', ascending = False)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The activity I have recorded in various chat types through time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = most_msgs.copy()\n",
    "df1 = df1.set_index('time')\n",
    "\n",
    "df2 = df1[df1['groupchat'] == True]\n",
    "df3 = df1[df1['groupchat'] == False]\n",
    "df4 = df1[df1['sender'] == my_name]\n",
    "\n",
    "df1 = df1[['text']]\n",
    "df2 = df2[['text']]\n",
    "df3 = df3[['text']]\n",
    "df4 = df4[['text']]\n",
    "\n",
    "df1 = df1.rename(columns={'text': 'All messages'})\n",
    "df2 = df2.rename(columns={'text': 'Groupchat messages'})\n",
    "df3 = df3.rename(columns={'text': 'Private messages'})\n",
    "df4 = df4.rename(columns={'text': 'My sent messages'})\n",
    "\n",
    "df1 = pd.concat([df1, df2, df3, df4])\n",
    "df1 = df1.resample('M').count()\n",
    "\n",
    "df1.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The peak in late 2015 is a new groupchat with two of my friends, the following dip and the continued low of groupchat messages is roughly 10k missing messages from the same chat and many messages missing from another groupchat.\n",
    "* The peak in Jul-Aug 2016 is the groupchat of a high school summer program in USA\n",
    "* The general low in Apr-Aug 2017 is roughly 10k missing messages from a single private conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My activity by the time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = all_msgs[all_msgs['sender'] == my_name]\n",
    "df = df[['time', 'groupchat']]\n",
    "\n",
    "df = df.set_index('time')\n",
    "df = df.resample('5min').sum()\n",
    "df.index = df.index.time\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.groupby('index')\n",
    "df = df.count()\n",
    "df = df.rename(columns={'groupchat': 'sent_messages'})\n",
    "\n",
    "df.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facebook provided all messages in either UTC+02 or UTC+03. ```format.py``` saved time without timezone information and pandas by default also does not concern itself with timezones. Despite that, without shifting the time forward about 3 hours, the following graph makes no sense as it would show an initial sharp rise in activity at around 4-5 in the morning while I never wake up that early. The same applies to the following graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messages by time of day every day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = all_msgs[all_msgs['sender'] == my_name]\n",
    "df = df[['time', 'groupchat']]\n",
    "df = df.set_index('time')\n",
    "df = df.resample('H').sum()\n",
    "pivot = df.pivot_table('groupchat', index=df.index.time, columns=df.index.date)\n",
    "pivot.plot(legend=False, alpha=0.10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There does not seem to be any consistent baseline, most activity seems to come in spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My activity by the day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = all_msgs[all_msgs['sender'] == my_name]\n",
    "df1 = df1[['time', 'groupchat']]\n",
    "df1 = df1.rename(columns={'groupchat': 'sent_messages', 'time': 'weekday'})\n",
    "df1 = df1.set_index('weekday')\n",
    "\n",
    "df2 = df1.copy()\n",
    "df2['weekday_number'] = df2.index.weekday\n",
    "df2 = df2[['weekday_number']]\n",
    "\n",
    "df1.index = df1.index.weekday_name\n",
    "df2.index = df2.index.weekday_name\n",
    "\n",
    "df1 = df1.groupby('weekday').count()\n",
    "df2 = df2.groupby('weekday').max()\n",
    "\n",
    "df1 = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "df1 = df1.sort_values('weekday_number')\n",
    "df1 = df1[['sent_messages']]\n",
    "\n",
    "maximum = df1['sent_messages'].values.max()\n",
    "df1.plot(kind='bar', ylim=(0, maximum + 3000));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, my activity is not the highest on the weekends, but on Mondays and Sundays (although the difference is not big)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words per message I send over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = most_msgs[most_msgs['sender'] == my_name]\n",
    "df = df[['time', 'text']]\n",
    "df['word_average'] = df['text'].str.strip().str.replace('  ', ' ').str.split(' ').apply(len)\n",
    "df = df[['time', 'word_average']]\n",
    "\n",
    "df = df.set_index('time')\n",
    "df = df.resample('w').mean()\n",
    "df = df.reset_index()\n",
    "\n",
    "timestamps = df['time'].values.astype(int64) // 10 ** 9 #strange hack\n",
    "a, b = polyfit(timestamps, df['word_average'], 1)\n",
    "\n",
    "x = range(timestamps.min(), timestamps.max()+1, 604800) #604 800 seconds in a week\n",
    "trend = pd.Series(a*x + b, name='trend')\n",
    "\n",
    "df = pd.concat([df, trend], axis=1)\n",
    "df = df.set_index('time')\n",
    "\n",
    "maximum = df['word_average'].values.max()\n",
    "df.plot(ylim=(0, maximum + 1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship between messages in a chat and the average number of words in one message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = all_msgs[['thread', 'text']]\n",
    "df2 = df1.copy()\n",
    "\n",
    "df1 = df1.rename(columns={'text': 'word_count'})\n",
    "df1 = df1.groupby('thread').count()\n",
    "\n",
    "df2['text'] = df2['text'].str.split(' ').apply(len)\n",
    "df2 = df2.rename(columns={'text': 'word_average'})\n",
    "df2 = df2.groupby('thread').mean()\n",
    "\n",
    "df1 = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "f, axarr = plt.subplots(1, 2, figsize=(13,4))\n",
    "axarr[0].scatter(x=df1['word_count'], y=df1['word_average'])\n",
    "axarr[1].scatter(x=df1['word_count'], y=df1['word_average'])\n",
    "axarr[1].set_yscale('log')\n",
    "axarr[1].set_xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the amount of messages sent increases, the average words per message converges somewhere between 4 and 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most common words for all messages and for me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = dict()\n",
    "punctuation = ['.',',',';','!','?',')']\n",
    "\n",
    "def read_words(message):\n",
    "    global words, punctuation\n",
    "    wordlist = message.lower().strip().replace('\\r', ' ').replace('\\n', ' ').replace('  ', ' ').split(' ')\n",
    "    \n",
    "    for word in wordlist:\n",
    "        \n",
    "        while len(word) > 1 and word[-1] in punctuation:\n",
    "            word = word[: len(word) - 1]\n",
    "        while len(word) > 1 and word[0] == '(':\n",
    "            word = word[1:]\n",
    "        \n",
    "        if word in words:\n",
    "            words[word] = words.get(word) + 1\n",
    "        else:\n",
    "            words[word] = 1\n",
    "\n",
    "def get_word_counts(df):\n",
    "    global words, punctuation\n",
    "    \n",
    "    df['text'].apply(read_words)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(words, orient='index')\n",
    "    words = dict()\n",
    "    \n",
    "    df.columns = ['count']\n",
    "    df = df.sort_values('count', ascending=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = all_msgs[['text']]\n",
    "df2 = (all_msgs[all_msgs['sender'] == my_name])[['text']]\n",
    "\n",
    "df1 = get_word_counts(df1)\n",
    "print(df1.head(20))\n",
    "print()\n",
    "\n",
    "df2 = get_word_counts(df2)\n",
    "print(df2.head(20))\n",
    "\n",
    "all_word_counts = df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only significant differences are my fondness of \":D\" and that I send non-text data (images, stickers, etc., represented by empty string) somewhat less."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acitivity of the biggest chats over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chats = chats.copy()\n",
    "\n",
    "groupchats = chats[chats['groupchat'] == True]\n",
    "chats = chats[chats['groupchat'] == False]\n",
    "# 8 most popular groupchats and regular chats\n",
    "important_chats = (chats[['thread', 'names']][:10].values.tolist() + \n",
    "                   groupchats[['thread', 'names']][:10].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = list() #contains tuples in the form (image or plot, title, optional plot type)\n",
    "\n",
    "# helper function to arrange images more compactly\n",
    "def display_queue_as_grid(figure_type, columns=3):\n",
    "    \n",
    "    rows = ceil(len(queue)/columns)\n",
    "    \n",
    "    for i in range(rows):\n",
    "        f, axarr = plt.subplots(1, columns, figsize=(18,5))\n",
    "        \n",
    "        for j in range(columns):\n",
    "\n",
    "            if len(queue) > 0:\n",
    "                \n",
    "                if figure_type == 'image':\n",
    "                    data = queue.pop(0)\n",
    "                    axarr[j].imshow(data[0], interpolation='bilinear')\n",
    "                    axarr[j].set_axis_off()\n",
    "                \n",
    "                else:\n",
    "                    data = queue.pop(0)\n",
    "                    data[0].plot(kind=data[2], ax=axarr[j], title=title)\n",
    "                \n",
    "                axarr[j].set_title(data[1])\n",
    "            \n",
    "            else:\n",
    "                axarr[j].set_axis_off()\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_timeseries(messages, title, people):\n",
    "    \n",
    "    if len(people.split(',')) < 12 : # if there is <=12 people, including me\n",
    "        # area plot with each person's contribution\n",
    "        df1s = []\n",
    "        people = people.split(',') + [my_name]\n",
    "        \n",
    "        for person in people:\n",
    "            \n",
    "            df1 = messages[messages['sender'] == person]\n",
    "            df1 = df1.set_index('time')[['groupchat']].sort_index()\n",
    "            df1 = df1.rename(columns={'groupchat': person})\n",
    "            df1s.append(df1)\n",
    "            \n",
    "        timeseries = pd.concat(df1s)\n",
    "        timeseries = timeseries.resample('M').count()\n",
    "        queue.append((timeseries, title, 'area'))\n",
    "        \n",
    "    else:\n",
    "        # just a simple timeseries of all sent messages\n",
    "        timeseries = messages.set_index('time')[['groupchat']].sort_index()\n",
    "        timeseries = timeseries.rename(columns={'groupchat': 'Sent messages'})\n",
    "        timeseries = timeseries.resample('w').count()\n",
    "        queue.append((timeseries, title, 'line'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for data in important_chats:\n",
    "    thread = data[0]\n",
    "    names = data[1]\n",
    "    chat = all_msgs[all_msgs['thread'] == thread]\n",
    "    chat = all_msgs[all_msgs['names'] == names]\n",
    "    \n",
    "    if len(thread) > 50:\n",
    "        title = thread[:50] + '...'\n",
    "    else:\n",
    "        title = thread\n",
    "    \n",
    "    create_timeseries(chat, title, names)\n",
    "    \n",
    "display_queue_as_grid('plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Missing chunks of messages can be observed in many chats here.\n",
    "* Some chat data also starts later than the chats actually did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average words per message by people in different chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_average_wpm(messages, title, people):\n",
    "    \n",
    "    averages = dict()\n",
    "    \n",
    "    if len(people.split(',')) > 12 : \n",
    "        # if there is >12 people including me, skip it\n",
    "        # because there are too many people to display\n",
    "        return\n",
    "    \n",
    "    people = people.split(',') + [my_name]\n",
    "        \n",
    "    for person in people:\n",
    "            \n",
    "        df = messages[messages['sender'] == person]\n",
    "        df2 = df.copy()\n",
    "        df2['word_average'] = df2['text'].str.strip().str.replace('  ', ' ').str.split(' ').apply(len)\n",
    "        df2 = df2[['word_average']]\n",
    "        averages[person] = round(df2.mean(), 2)\n",
    "    \n",
    "    df = messages.copy()\n",
    "    df['word_average'] = df['text'].str.strip().str.replace('  ', ' ').str.split(' ').apply(len)\n",
    "    df = df[['word_average']]\n",
    "    #averages['chat'] = round(df.mean(), 2)\n",
    "    df = pd.DataFrame.from_dict(averages, orient='index')\n",
    "    \n",
    "    print('###' + title + ':' + '\\n')\n",
    "    print(df)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for data in important_chats:\n",
    "    thread = data[0]\n",
    "    names = data[1]\n",
    "    chat = all_msgs[all_msgs['thread'] == thread]\n",
    "    chat = all_msgs[all_msgs['names'] == names]\n",
    "    \n",
    "    if len(thread) > 50:\n",
    "        title = thread[:50] + '...'\n",
    "    else:\n",
    "        title = thread\n",
    "    \n",
    "    print_average_wpm(chat, title, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No significant data exists for other people, but as one might expect, my wordiness seems to depend greatly on the chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most characteristic words of the biggest chats\n",
    "(Calculated as words occurring much more often in the chat as compared to the entire dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_word_counts = all_word_counts[all_word_counts['count'] >= 6]\n",
    "total_important_words = all_word_counts['count'].sum()\n",
    "word_frequencies = important_word_counts['count'] / total_important_words\n",
    "word_frequencies = word_frequencies.rename('global_frequency')\n",
    "\n",
    "def remove_longs(word):\n",
    "    # get rid of very long words such as URLs that ruin wordcluds\n",
    "    if len(word) < 18:\n",
    "        return word\n",
    "    else:\n",
    "        return nan\n",
    "\n",
    "def plot_most_characteristic_words(messages, title):\n",
    "    df = get_word_counts(messages)\n",
    "    \n",
    "    df['frequency'] = df['count'] / df['count'].sum()\n",
    "    df = df[df['count'] >= 6]\n",
    "    \n",
    "    df = pd.concat([df, word_frequencies], axis=1)\n",
    "    # drop all columns where there isn't a value in 'frequency'\n",
    "    df = df.dropna(axis=0, how='any')\n",
    "    \n",
    "    df['quotient'] = df['frequency'] / df['global_frequency']\n",
    "    df['word'] = df.index.to_series().apply(remove_longs)\n",
    "    df = df.dropna(axis=0, how='any')\n",
    "    df = df.set_index('word')\n",
    "    \n",
    "    df = df.sort_values(['quotient', 'count'], ascending=[False, False])\n",
    "    df = df[['quotient']].head(80)\n",
    "    \n",
    "    dictionary = df['quotient'].to_dict()\n",
    "    wordcloud = WordCloud(height=300, width=400, max_font_size=55).generate_from_frequencies(dictionary)\n",
    "    \n",
    "    queue.append((wordcloud, title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for data in important_chats:\n",
    "    thread = data[0]\n",
    "    names = data[1]\n",
    "    chat = all_msgs[all_msgs['thread'] == thread]\n",
    "    chat = all_msgs[all_msgs['names'] == names]\n",
    "    \n",
    "    if len(thread) > 50:\n",
    "        title = thread[:50] + '...'\n",
    "    else:\n",
    "        title = thread\n",
    "    \n",
    "    plot_most_characteristic_words(chat, title)\n",
    "\n",
    "display_queue_as_grid('image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most characteristic words of the most occurring people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = all_msgs.copy()[['sender', 'groupchat']]\n",
    "df = df.groupby('sender').count()\n",
    "df = df.rename(columns={'groupchat': 'messages_available'})\n",
    "df = df.sort_values('messages_available', ascending = False)\n",
    "most_occurring_people = df[df['messages_available'] >= 500].index.tolist()\n",
    "\n",
    "for person in most_occurring_people[:20]:\n",
    "    messages = all_msgs[all_msgs['sender'] == person]\n",
    "    plot_most_characteristic_words(messages, person)\n",
    "\n",
    "display_queue_as_grid('image')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
